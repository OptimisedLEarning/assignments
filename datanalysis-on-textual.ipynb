{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-21T09:45:11.643004Z","iopub.execute_input":"2024-03-21T09:45:11.643799Z","iopub.status.idle":"2024-03-21T09:45:13.046751Z","shell.execute_reply.started":"2024-03-21T09:45:11.643762Z","shell.execute_reply":"2024-03-21T09:45:13.045409Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"df=pd.read_csv(\"/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\")\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:45:13.048624Z","iopub.execute_input":"2024-03-21T09:45:13.049101Z","iopub.status.idle":"2024-03-21T09:45:14.801930Z","shell.execute_reply.started":"2024-03-21T09:45:13.049069Z","shell.execute_reply":"2024-03-21T09:45:14.800567Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                              review sentiment\n0  One of the other reviewers has mentioned that ...  positive\n1  A wonderful little production. <br /><br />The...  positive\n2  I thought this was a wonderful way to spend ti...  positive\n3  Basically there's a family where a little boy ...  negative\n4  Petter Mattei's \"Love in the Time of Money\" is...  positive","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>One of the other reviewers has mentioned that ...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I thought this was a wonderful way to spend ti...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Basically there's a family where a little boy ...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:45:14.803691Z","iopub.execute_input":"2024-03-21T09:45:14.804143Z","iopub.status.idle":"2024-03-21T09:45:14.858140Z","shell.execute_reply.started":"2024-03-21T09:45:14.804113Z","shell.execute_reply":"2024-03-21T09:45:14.856588Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 50000 entries, 0 to 49999\nData columns (total 2 columns):\n #   Column     Non-Null Count  Dtype \n---  ------     --------------  ----- \n 0   review     50000 non-null  object\n 1   sentiment  50000 non-null  object\ndtypes: object(2)\nmemory usage: 781.4+ KB\n","output_type":"stream"}]},{"cell_type":"code","source":"df[\"review\"][0]  # first riview","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:45:14.861625Z","iopub.execute_input":"2024-03-21T09:45:14.862107Z","iopub.status.idle":"2024-03-21T09:45:14.871115Z","shell.execute_reply.started":"2024-03-21T09:45:14.862066Z","shell.execute_reply":"2024-03-21T09:45:14.869686Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"\"One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\""},"metadata":{}}]},{"cell_type":"markdown","source":"# steps to  follow \n# DATA gathering \n# Cleaning steps-\n1 uniform data  means lowercasing \n2 remove leading and trainling spaces \n3 removing  html tags\n4removing urls as it does not convey any meaning \n5 Exapnding abbriviation example (who'll coudn't ,you'll ,doesn't  we do does not )\n6 spelling correction (nite ,nyt to night)\n7 removing puntuation marks (! ,?)\n8 reming special charters also (@ #)\n# Preprocess \n1 tokenization i.e dividing the sentence into parts\n2 stop word removal (example and I ,could,have  bcz they dont contribute in meaning )\n3 stemming(dance ,dancing, ,danced we make it to dance to make it  the main meaning is dance ) \n\n# Eda\n# Make some feature (Ex no. of words)\n# vectorization means we convert the text to number (1 BoW  2 TfIdf 3word to wick)\n\n# untill here data analysis is done ","metadata":{}},{"cell_type":"code","source":"df.duplicated().sum()","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:45:14.872784Z","iopub.execute_input":"2024-03-21T09:45:14.873167Z","iopub.status.idle":"2024-03-21T09:45:15.083629Z","shell.execute_reply.started":"2024-03-21T09:45:14.873135Z","shell.execute_reply":"2024-03-21T09:45:15.082359Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"418"},"metadata":{}}]},{"cell_type":"code","source":"df= df.drop_duplicates()","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:45:15.088239Z","iopub.execute_input":"2024-03-21T09:45:15.088598Z","iopub.status.idle":"2024-03-21T09:45:15.280457Z","shell.execute_reply.started":"2024-03-21T09:45:15.088569Z","shell.execute_reply":"2024-03-21T09:45:15.279228Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"#cleaning \n# lower_case\ndf[\"review\"] = df[\"review\"].str.lower()\ndf.sample(3)","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:45:15.282105Z","iopub.execute_input":"2024-03-21T09:45:15.282706Z","iopub.status.idle":"2024-03-21T09:45:15.518227Z","shell.execute_reply.started":"2024-03-21T09:45:15.282663Z","shell.execute_reply":"2024-03-21T09:45:15.517097Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                                                  review sentiment\n37861  oh my god i am lost now i know everything this...  negative\n2945   this movie raises a number of pressing questio...  negative\n48871  \"the screaming skull\" opens with a warning and...  negative","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>37861</th>\n      <td>oh my god i am lost now i know everything this...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>2945</th>\n      <td>this movie raises a number of pressing questio...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>48871</th>\n      <td>\"the screaming skull\" opens with a warning and...</td>\n      <td>negative</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# removing white spacees \n\ndf[\"review\"]=df[\"review\"].str.strip()\n","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:45:15.522080Z","iopub.execute_input":"2024-03-21T09:45:15.523443Z","iopub.status.idle":"2024-03-21T09:45:15.561548Z","shell.execute_reply.started":"2024-03-21T09:45:15.523369Z","shell.execute_reply":"2024-03-21T09:45:15.560533Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"#removing html Tags \ndf['review'] = df['review'].str.replace(r'<.*?>','')","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:45:15.563322Z","iopub.execute_input":"2024-03-21T09:45:15.564102Z","iopub.status.idle":"2024-03-21T09:45:15.628187Z","shell.execute_reply.started":"2024-03-21T09:45:15.564060Z","shell.execute_reply":"2024-03-21T09:45:15.626795Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#removing Urls now \nimport re\ndef remove_url(data):\n    data=re.sub(r\"https?://\\S+|www\\.\\S+\",'',data)\n    return data","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:45:15.632841Z","iopub.execute_input":"2024-03-21T09:45:15.633711Z","iopub.status.idle":"2024-03-21T09:45:15.639054Z","shell.execute_reply.started":"2024-03-21T09:45:15.633665Z","shell.execute_reply":"2024-03-21T09:45:15.637827Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"remove_url(\"ro link on https://ak.com\")","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:45:15.640742Z","iopub.execute_input":"2024-03-21T09:45:15.641100Z","iopub.status.idle":"2024-03-21T09:45:15.654140Z","shell.execute_reply.started":"2024-03-21T09:45:15.641063Z","shell.execute_reply":"2024-03-21T09:45:15.653075Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"'ro link on '"},"metadata":{}}]},{"cell_type":"code","source":"df[\"review\"].str.replace(r\"https?://\\S+|www\\.\\S+\",'')","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:45:15.655509Z","iopub.execute_input":"2024-03-21T09:45:15.656289Z","iopub.status.idle":"2024-03-21T09:45:15.722448Z","shell.execute_reply.started":"2024-03-21T09:45:15.656241Z","shell.execute_reply":"2024-03-21T09:45:15.721445Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"0        one of the other reviewers has mentioned that ...\n1        a wonderful little production. <br /><br />the...\n2        i thought this was a wonderful way to spend ti...\n3        basically there's a family where a little boy ...\n4        petter mattei's \"love in the time of money\" is...\n                               ...                        \n49995    i thought this movie did a down right good job...\n49996    bad plot, bad dialogue, bad acting, idiotic di...\n49997    i am a catholic taught in parochial elementary...\n49998    i'm going to have to disagree with the previou...\n49999    no one expects the star trek movies to be high...\nName: review, Length: 49582, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"#contains is used to check where are the urls \ndf[df[\"review\"].str.contains(r\"https?://\\S+|www\\.\\S+\",'')]","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:45:15.725413Z","iopub.execute_input":"2024-03-21T09:45:15.726262Z","iopub.status.idle":"2024-03-21T09:45:20.409828Z","shell.execute_reply.started":"2024-03-21T09:45:15.726223Z","shell.execute_reply":"2024-03-21T09:45:20.408711Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"                                                  review sentiment\n742    mario lewis of the competitive enterprise inst...  negative\n907    following directly from where the story left o...  positive\n1088   this quasi j-horror film followed a young woma...  negative\n1137   i really think i should make my case and have ...  positive\n1141   this show has to be my favorite out of all the...  positive\n...                                                  ...       ...\n48887  trite and unoriginal. it's like someone watche...  negative\n49063  trick or treat, quickie review this zany romp ...  positive\n49596  this is absolutely the best 80s cartoon ever, ...  positive\n49637  if you liked the richard chamberlain version o...  positive\n49951  \"scientists at a remote lab experiment on (ins...  negative\n\n[195 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>742</th>\n      <td>mario lewis of the competitive enterprise inst...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>907</th>\n      <td>following directly from where the story left o...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1088</th>\n      <td>this quasi j-horror film followed a young woma...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>1137</th>\n      <td>i really think i should make my case and have ...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1141</th>\n      <td>this show has to be my favorite out of all the...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>48887</th>\n      <td>trite and unoriginal. it's like someone watche...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>49063</th>\n      <td>trick or treat, quickie review this zany romp ...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>49596</th>\n      <td>this is absolutely the best 80s cartoon ever, ...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>49637</th>\n      <td>if you liked the richard chamberlain version o...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>49951</th>\n      <td>\"scientists at a remote lab experiment on (ins...</td>\n      <td>negative</td>\n    </tr>\n  </tbody>\n</table>\n<p>195 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df[df[\"review\"].str.contains(r\"https?://\\S+|www\\.\\S+\",'')].iloc[0].values","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:45:20.412021Z","iopub.execute_input":"2024-03-21T09:45:20.412877Z","iopub.status.idle":"2024-03-21T09:45:25.098942Z","shell.execute_reply.started":"2024-03-21T09:45:20.412832Z","shell.execute_reply":"2024-03-21T09:45:25.097598Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"array(['mario lewis of the competitive enterprise institute has written a definitive 120-page point-by-point, line-by-line refutation of this mendacious film, which should be titled a convenient lie. the website address where his debunking report, which is titled \"a skeptic\\'s guide to an inconvenient truth\" can be found at is :www.cei.org. a shorter 10-page version can be found at: www.cei.org/pdf/5539.pdf once you read those demolitions, you\\'ll realize that alleged \"global warming\" is no more real or dangerous than the y2k scare of 1999, which gore also endorsed, as he did the pseudo-scientific film the day after tomorrow, which was based on a book written by alleged ufo abductee whitley strieber. as james \"the amazing\" randi does to psychics, and philip klass does to ufos, and gerald posner does to jfk conspir-idiocy theories, so does mario lewis does to al gore\\'s movie and the whole \"global warming\" scam.',\n       'negative'], dtype=object)"},"metadata":{}}]},{"cell_type":"code","source":"df[df[\"review\"].str.contains(r\"https?://\\S+|www\\.\\S+\",'')].iloc[13].values","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:45:25.100822Z","iopub.execute_input":"2024-03-21T09:45:25.101282Z","iopub.status.idle":"2024-03-21T09:45:29.779298Z","shell.execute_reply.started":"2024-03-21T09:45:25.101241Z","shell.execute_reply":"2024-03-21T09:45:29.777643Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"array([\"love trap is not a short, it's quite obviously a full length feature film with a running time of 105 minutes.<br /><br />while i'm writing this, i might as well talk a bit more about love trap. i'm frequently asked what makes love trap different... this is how i respond to that question: 1) it introduces characters - one in particular - that have never been seen before in film, period.<br /><br />2) it reveals more truth about love, and delves more deeply into the very concept of love, than any other u.s. film ever made, in my humble opinion.<br /><br />3) structurally, as in the way the story is told, it is unlike any love story you've ever seen.<br /><br />4) it offers extremely timely insights on various cultural issues, both within and outside the black community.<br /><br />over time, people will come to see love trap as about as wholly an original work as possible in this era, delightfully refreshing, authentic and honest. it is a rare morality play full of food for thought.<br /><br />please visit www.lovetrapmovie.com for complete and accurate info about this film.\",\n       'positive'], dtype=object)"},"metadata":{}}]},{"cell_type":"code","source":"# Finally after checking im going to remove the values where url exist\n\ndf[\"review\"]=df[\"review\"].str.replace(r\"https?://\\S+|www\\.\\S+\",'')\ndf.sample(5)","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:45:29.781147Z","iopub.execute_input":"2024-03-21T09:45:29.781980Z","iopub.status.idle":"2024-03-21T09:45:29.855765Z","shell.execute_reply.started":"2024-03-21T09:45:29.781924Z","shell.execute_reply":"2024-03-21T09:45:29.854453Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"                                                  review sentiment\n25884  this movie could very well have been a propaga...  negative\n10713  i bought this dvd for $1 at walmart. after see...  negative\n11121  i love occult horror, and the great british ha...  positive\n9438   i searched out this one after seeing the hilar...  positive\n18582  this movie is total dumbness incarnate. yet, i...  negative","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>25884</th>\n      <td>this movie could very well have been a propaga...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>10713</th>\n      <td>i bought this dvd for $1 at walmart. after see...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>11121</th>\n      <td>i love occult horror, and the great british ha...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>9438</th>\n      <td>i searched out this one after seeing the hilar...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>18582</th>\n      <td>this movie is total dumbness incarnate. yet, i...</td>\n      <td>negative</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# code to check if a review contains an URL\ndf[df['review'].str.contains(r\"https?://\\S+|www\\.\\S+\")].iloc[4].values","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:45:29.857343Z","iopub.execute_input":"2024-03-21T09:45:29.857726Z","iopub.status.idle":"2024-03-21T09:45:31.464565Z","shell.execute_reply.started":"2024-03-21T09:45:29.857695Z","shell.execute_reply":"2024-03-21T09:45:31.463286Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"array([\"this show has to be my favorite out of all the 80's horror tv shows. like tales from the darkside, also from the same creators, this show is a rare gem. if you agree with me, please sign this petition i started, to get the word out for monsters and get it out on dvd. here is the petition address: www.petitiononline.com/19784444/petition.html some of my favorite episodes would have to be glim glim, and rain dance. i also loved the opening intro with the monster family. that used to creep me out! one of the things i would have to ask the dvd creators to include would be the organ sound heard right before where the commercial break would be. i don't know if any of you remember that part but that's one of the main things that brings back memories to me. i mean, come on! war of the worlds the tv series already has been released on dvd, so i say monsters, and also tales from the darkside, and friday the 13th the series should be released too! we the fans need to speak our minds! we need this awesome show on dvd so please spread the word!!!\",\n       'positive'], dtype=object)"},"metadata":{}}]},{"cell_type":"code","source":"# expanding abbvr\n\n# expand \n\ndef remove_abb(data):\n    data = re.sub(r\"he's\", \"he is\", data)\n    data = re.sub(r\"there's\", \"there is\", data)\n    data = re.sub(r\"We're\", \"We are\", data)\n    data = re.sub(r\"That's\", \"That is\", data)\n    data = re.sub(r\"won't\", \"will not\", data)\n    data = re.sub(r\"they're\", \"they are\", data)\n    data = re.sub(r\"Can't\", \"Cannot\", data)\n    data = re.sub(r\"wasn't\", \"was not\", data)\n    data = re.sub(r\"don\\x89Ûªt\", \"do not\", data)\n    data= re.sub(r\"aren't\", \"are not\", data)\n    data = re.sub(r\"isn't\", \"is not\", data)\n    data = re.sub(r\"What's\", \"What is\", data)\n    data = re.sub(r\"haven't\", \"have not\", data)\n    data = re.sub(r\"hasn't\", \"has not\", data)\n    data = re.sub(r\"There's\", \"There is\", data)\n    data = re.sub(r\"He's\", \"He is\", data)\n    data = re.sub(r\"It's\", \"It is\", data)\n    data = re.sub(r\"You're\", \"You are\", data)\n    data = re.sub(r\"I'M\", \"I am\", data)\n    data = re.sub(r\"shouldn't\", \"should not\", data)\n    data = re.sub(r\"wouldn't\", \"would not\", data)\n    data = re.sub(r\"i'm\", \"I am\", data)\n    data = re.sub(r\"I\\x89Ûªm\", \"I am\", data)\n    data = re.sub(r\"I'm\", \"I am\", data)\n    data = re.sub(r\"Isn't\", \"is not\", data)\n    data = re.sub(r\"Here's\", \"Here is\", data)\n    data = re.sub(r\"you've\", \"you have\", data)\n    data = re.sub(r\"you\\x89Ûªve\", \"you have\", data)\n    data = re.sub(r\"we're\", \"we are\", data)\n    data = re.sub(r\"what's\", \"what is\", data)\n    data = re.sub(r\"couldn't\", \"could not\", data)\n    data = re.sub(r\"we've\", \"we have\", data)\n    data = re.sub(r\"it\\x89Ûªs\", \"it is\", data)\n    data = re.sub(r\"doesn\\x89Ûªt\", \"does not\", data)\n    data = re.sub(r\"It\\x89Ûªs\", \"It is\", data)\n    data = re.sub(r\"Here\\x89Ûªs\", \"Here is\", data)\n    data = re.sub(r\"who's\", \"who is\", data)\n    data = re.sub(r\"I\\x89Ûªve\", \"I have\", data)\n    data = re.sub(r\"y'all\", \"you all\", data)\n    data = re.sub(r\"can\\x89Ûªt\", \"cannot\", data)\n    data = re.sub(r\"would've\", \"would have\", data)\n    data = re.sub(r\"it'll\", \"it will\", data)\n    data = re.sub(r\"we'll\", \"we will\", data)\n    data = re.sub(r\"wouldn\\x89Ûªt\", \"would not\", data)\n    data = re.sub(r\"We've\", \"We have\", data)\n    data = re.sub(r\"he'll\", \"he will\", data)\n    data = re.sub(r\"Y'all\", \"You all\", data)\n    data = re.sub(r\"Weren't\", \"Were not\", data)\n    data = re.sub(r\"Didn't\", \"Did not\", data)\n    data = re.sub(r\"they'll\", \"they will\", data)\n    data = re.sub(r\"they'd\", \"they would\", data)\n    data = re.sub(r\"DON'T\", \"DO NOT\", data)\n    data = re.sub(r\"That\\x89Ûªs\", \"That is\", data)\n    data = re.sub(r\"they've\", \"they have\", data)\n    data = re.sub(r\"i'd\", \"I would\", data)\n    data = re.sub(r\"should've\", \"should have\", data)\n    data = re.sub(r\"You\\x89Ûªre\", \"You are\", data)\n    data = re.sub(r\"where's\", \"where is\", data)\n    data = re.sub(r\"Don\\x89Ûªt\", \"Do not\", data)\n    data = re.sub(r\"we'd\", \"we would\", data)\n    data = re.sub(r\"i'll\", \"I will\", data)\n    data = re.sub(r\"weren't\", \"were not\", data)\n    data = re.sub(r\"They're\", \"They are\", data)\n    data = re.sub(r\"Can\\x89Ûªt\", \"Cannot\", data)\n    data = re.sub(r\"you\\x89Ûªll\", \"you will\", data)\n    data = re.sub(r\"I\\x89Ûªd\", \"I would\", data)\n    data = re.sub(r\"let's\", \"let us\", data)\n    data = re.sub(r\"it's\", \"it is\", data)\n    data = re.sub(r\"can't\", \"cannot\", data)\n    data = re.sub(r\"don't\", \"do not\", data)\n    data = re.sub(r\"you're\", \"you are\", data)\n    data = re.sub(r\"i've\", \"I have\", data)\n    data = re.sub(r\"that's\", \"that is\", data)\n    data = re.sub(r\"i'll\", \"I will\", data)\n    data = re.sub(r\"doesn't\", \"does not\",data)\n    data = re.sub(r\"i'd\", \"I would\", data)\n    data = re.sub(r\"didn't\", \"did not\", data)\n    data = re.sub(r\"ain't\", \"am not\", data)\n    data = re.sub(r\"you'll\", \"you will\", data)\n    data = re.sub(r\"I've\", \"I have\", data)\n    data = re.sub(r\"Don't\", \"do not\", data)\n    data = re.sub(r\"I'll\", \"I will\", data)\n    data = re.sub(r\"I'd\", \"I would\", data)\n    data = re.sub(r\"Let's\", \"Let us\", data)\n    data = re.sub(r\"you'd\", \"You would\", data)\n    data = re.sub(r\"It's\", \"It is\", data)\n    data = re.sub(r\"Ain't\", \"am not\", data)\n    data = re.sub(r\"Haven't\", \"Have not\", data)\n    data = re.sub(r\"Could've\", \"Could have\", data)\n    data = re.sub(r\"youve\", \"you have\", data)  \n    data = re.sub(r\"donå«t\", \"do not\", data)\n    \n    return data","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:47:47.686720Z","iopub.execute_input":"2024-03-21T09:47:47.687110Z","iopub.status.idle":"2024-03-21T09:47:47.720102Z","shell.execute_reply.started":"2024-03-21T09:47:47.687082Z","shell.execute_reply":"2024-03-21T09:47:47.718559Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"df[\"review\"]=df[\"review\"].apply(remove_abb)","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:51:11.886538Z","iopub.execute_input":"2024-03-21T09:51:11.886934Z","iopub.status.idle":"2024-03-21T09:51:23.486126Z","shell.execute_reply.started":"2024-03-21T09:51:11.886903Z","shell.execute_reply":"2024-03-21T09:51:23.484481Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"df[\"review\"]","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:51:28.920558Z","iopub.execute_input":"2024-03-21T09:51:28.921297Z","iopub.status.idle":"2024-03-21T09:51:28.931356Z","shell.execute_reply.started":"2024-03-21T09:51:28.921252Z","shell.execute_reply":"2024-03-21T09:51:28.930085Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"0        one of the other reviewers has mentioned that ...\n1        a wonderful little production. <br /><br />the...\n2        i thought this was a wonderful way to spend ti...\n3        basically there is a family where a little boy...\n4        petter mattei's \"love in the time of money\" is...\n                               ...                        \n49995    i thought this movie did a down right good job...\n49996    bad plot, bad dialogue, bad acting, idiotic di...\n49997    i am a catholic taught in parochial elementary...\n49998    I am going to have to disagree with the previo...\n49999    no one expects the star trek movies to be high...\nName: review, Length: 49582, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"from textblob import TextBlob\ntext=\"hi I can dve at nite\"\nTextBlob(text).correct().string","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:53:24.655714Z","iopub.execute_input":"2024-03-21T09:53:24.656666Z","iopub.status.idle":"2024-03-21T09:53:24.664199Z","shell.execute_reply.started":"2024-03-21T09:53:24.656631Z","shell.execute_reply":"2024-03-21T09:53:24.662827Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"'hi I can due at note'"},"metadata":{}}]},{"cell_type":"code","source":"def spell_correction(text):\n    return TextBlob(text).correct().string","metadata":{"execution":{"iopub.status.busy":"2024-03-21T09:54:21.966281Z","iopub.execute_input":"2024-03-21T09:54:21.966734Z","iopub.status.idle":"2024-03-21T09:54:21.972814Z","shell.execute_reply.started":"2024-03-21T09:54:21.966703Z","shell.execute_reply":"2024-03-21T09:54:21.971492Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"df[\"review\"].apply(spell_correction)","metadata":{"execution":{"iopub.status.busy":"2024-03-21T10:15:39.763694Z","iopub.execute_input":"2024-03-21T10:15:39.764361Z","iopub.status.idle":"2024-03-21T11:40:54.332562Z","shell.execute_reply.started":"2024-03-21T10:15:39.764330Z","shell.execute_reply":"2024-03-21T11:40:54.329712Z"},"trusted":true},"execution_count":33,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreview\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspell_correction\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/series.py:4915\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4780\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4781\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4782\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4787\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4788\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4790\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4791\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4906\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4907\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4908\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4909\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4910\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4911\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4912\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4913\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4914\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 4915\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n","File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n","Cell \u001b[0;32mIn[30], line 2\u001b[0m, in \u001b[0;36mspell_correction\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mspell_correction\u001b[39m(text):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTextBlob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorrect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mstring\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/textblob/blob.py:549\u001b[0m, in \u001b[0;36mBaseBlob.correct\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    547\u001b[0m tokens \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mtokenize\u001b[38;5;241m.\u001b[39mregexp_tokenize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+|[^\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms]|\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    548\u001b[0m corrected \u001b[38;5;241m=\u001b[39m (Word(w)\u001b[38;5;241m.\u001b[39mcorrect() \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m tokens)\n\u001b[0;32m--> 549\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorrected\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m(ret)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/textblob/blob.py:548\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[38;5;66;03m# regex matches: word or punctuation or whitespace\u001b[39;00m\n\u001b[1;32m    547\u001b[0m tokens \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mtokenize\u001b[38;5;241m.\u001b[39mregexp_tokenize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+|[^\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms]|\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 548\u001b[0m corrected \u001b[38;5;241m=\u001b[39m (\u001b[43mWord\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorrect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m tokens)\n\u001b[1;32m    549\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(corrected)\n\u001b[1;32m    550\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m(ret)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/textblob/blob.py:115\u001b[0m, in \u001b[0;36mWord.correct\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcorrect\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    110\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Correct the spelling of the word. Returns the word with the highest\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;124;03m    confidence using the spelling corrector.\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 0.6.0\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Word(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspellcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/textblob/blob.py:107\u001b[0m, in \u001b[0;36mWord.spellcheck\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mspellcheck\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     99\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a list of (word, confidence) tuples of spelling corrections.\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03m    Based on: Peter Norvig, \"How to Write a Spelling Corrector\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 0.6.0\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msuggest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstring\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/textblob/en/__init__.py:118\u001b[0m, in \u001b[0;36msuggest\u001b[0;34m(w)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msuggest\u001b[39m(w):\n\u001b[1;32m    117\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns a list of (word, confidence)-tuples of spelling corrections.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mspelling\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuggest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/textblob/_text.py:1692\u001b[0m, in \u001b[0;36mSpelling.suggest\u001b[0;34m(self, w)\u001b[0m\n\u001b[1;32m   1687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m w\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39misdigit():\n\u001b[1;32m   1688\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [(w, \u001b[38;5;241m1.0\u001b[39m)]  \u001b[38;5;66;03m# 1.5\u001b[39;00m\n\u001b[1;32m   1689\u001b[0m candidates \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1690\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_known([w])\n\u001b[1;32m   1691\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_known(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_edit1(w))\n\u001b[0;32m-> 1692\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_known(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_edit2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1693\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m [w]\n\u001b[1;32m   1694\u001b[0m )\n\u001b[1;32m   1695\u001b[0m candidates \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget(c, \u001b[38;5;241m0.0\u001b[39m), c) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m candidates]\n\u001b[1;32m   1696\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28msum\u001b[39m(p \u001b[38;5;28;01mfor\u001b[39;00m p, word \u001b[38;5;129;01min\u001b[39;00m candidates) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m1\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/textblob/_text.py:1667\u001b[0m, in \u001b[0;36mSpelling._edit2\u001b[0;34m(self, w)\u001b[0m\n\u001b[1;32m   1664\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns a set of words with edit distance 2 from the given word\"\"\"\u001b[39;00m\n\u001b[1;32m   1665\u001b[0m \u001b[38;5;66;03m# Of all spelling errors, 99% is covered by edit distance 2.\u001b[39;00m\n\u001b[1;32m   1666\u001b[0m \u001b[38;5;66;03m# Only keep candidates that are actually known words (20% speedup).\u001b[39;00m\n\u001b[0;32m-> 1667\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43me2\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43me1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_edit1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43me2\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_edit1\u001b[49m\u001b[43m(\u001b[49m\u001b[43me1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43me2\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/textblob/_text.py:1667\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1664\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns a set of words with edit distance 2 from the given word\"\"\"\u001b[39;00m\n\u001b[1;32m   1665\u001b[0m \u001b[38;5;66;03m# Of all spelling errors, 99% is covered by edit distance 2.\u001b[39;00m\n\u001b[1;32m   1666\u001b[0m \u001b[38;5;66;03m# Only keep candidates that are actually known words (20% speedup).\u001b[39;00m\n\u001b[0;32m-> 1667\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mset\u001b[39m(e2 \u001b[38;5;28;01mfor\u001b[39;00m e1 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_edit1(w) \u001b[38;5;28;01mfor\u001b[39;00m e2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_edit1\u001b[49m\u001b[43m(\u001b[49m\u001b[43me1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m e2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/textblob/_text.py:1661\u001b[0m, in \u001b[0;36mSpelling._edit1\u001b[0;34m(self, w)\u001b[0m\n\u001b[1;32m   1654\u001b[0m split \u001b[38;5;241m=\u001b[39m [(w[:i], w[i:]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(w) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)]\n\u001b[1;32m   1655\u001b[0m delete, transpose, replace, insert \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1656\u001b[0m     [a \u001b[38;5;241m+\u001b[39m b[\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;28;01mfor\u001b[39;00m a, b \u001b[38;5;129;01min\u001b[39;00m split \u001b[38;5;28;01mif\u001b[39;00m b],\n\u001b[1;32m   1657\u001b[0m     [a \u001b[38;5;241m+\u001b[39m b[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m b[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m b[\u001b[38;5;241m2\u001b[39m:] \u001b[38;5;28;01mfor\u001b[39;00m a, b \u001b[38;5;129;01min\u001b[39;00m split \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(b) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m   1658\u001b[0m     [a \u001b[38;5;241m+\u001b[39m c \u001b[38;5;241m+\u001b[39m b[\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;28;01mfor\u001b[39;00m a, b \u001b[38;5;129;01min\u001b[39;00m split \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m Spelling\u001b[38;5;241m.\u001b[39mALPHA \u001b[38;5;28;01mif\u001b[39;00m b],\n\u001b[1;32m   1659\u001b[0m     [a \u001b[38;5;241m+\u001b[39m c \u001b[38;5;241m+\u001b[39m b[\u001b[38;5;241m0\u001b[39m:] \u001b[38;5;28;01mfor\u001b[39;00m a, b \u001b[38;5;129;01min\u001b[39;00m split \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m Spelling\u001b[38;5;241m.\u001b[39mALPHA],\n\u001b[1;32m   1660\u001b[0m )\n\u001b[0;32m-> 1661\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdelete\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtranspose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mreplace\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minsert\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"# puntuation handliing \nimport string\nstring.punctuation","metadata":{"execution":{"iopub.status.busy":"2024-03-21T11:40:54.334127Z","iopub.status.idle":"2024-03-21T11:40:54.334774Z","shell.execute_reply.started":"2024-03-21T11:40:54.334513Z","shell.execute_reply":"2024-03-21T11:40:54.334551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def remove_puncution(text):\n    for i in string.punctuation:\n        if i in text:\n            text=text.replace(i,\"\")\n    return text        ","metadata":{"execution":{"iopub.status.busy":"2024-03-21T11:40:54.335992Z","iopub.status.idle":"2024-03-21T11:40:54.336377Z","shell.execute_reply.started":"2024-03-21T11:40:54.336190Z","shell.execute_reply":"2024-03-21T11:40:54.336206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"review\"]=df[\"review\"].apply(remove_puntuation)\ndf[\"review\"].head()","metadata":{"execution":{"iopub.status.busy":"2024-03-21T11:40:54.337740Z","iopub.status.idle":"2024-03-21T11:40:54.338151Z","shell.execute_reply.started":"2024-03-21T11:40:54.337936Z","shell.execute_reply":"2024-03-21T11:40:54.337952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"review\"]=df[\"review\"].str.replace(r\"[^\\w\\s]\",'')","metadata":{"execution":{"iopub.status.busy":"2024-03-21T11:40:54.339294Z","iopub.status.idle":"2024-03-21T11:40:54.339710Z","shell.execute_reply.started":"2024-03-21T11:40:54.339514Z","shell.execute_reply":"2024-03-21T11:40:54.339534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing  \ntokenization \nremoving stopwords ","metadata":{}},{"cell_type":"code","source":"# Tokenizaion have two types sentence level and word level\n# usally word level tokenization is used \n\nfrom nltk.tokenize import word tokenize\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-21T11:40:54.340881Z","iopub.status.idle":"2024-03-21T11:40:54.341282Z","shell.execute_reply.started":"2024-03-21T11:40:54.341091Z","shell.execute_reply":"2024-03-21T11:40:54.341108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"tokenized_review\"]= df[\"review\"].apply(word tokenize)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-21T11:40:54.343459Z","iopub.status.idle":"2024-03-21T11:40:54.344028Z","shell.execute_reply.started":"2024-03-21T11:40:54.343726Z","shell.execute_reply":"2024-03-21T11:40:54.343752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# stopword removal \nfrom nltk.corpus import stopwords","metadata":{"execution":{"iopub.status.busy":"2024-03-21T11:40:54.345786Z","iopub.status.idle":"2024-03-21T11:40:54.346365Z","shell.execute_reply.started":"2024-03-21T11:40:54.346079Z","shell.execute_reply":"2024-03-21T11:40:54.346103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(stopwords.words(\"english\"))","metadata":{"execution":{"iopub.status.busy":"2024-03-21T11:40:54.348991Z","iopub.status.idle":"2024-03-21T11:40:54.349380Z","shell.execute_reply.started":"2024-03-21T11:40:54.349193Z","shell.execute_reply":"2024-03-21T11:40:54.349209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def remove_stopwords(text):\n    L = []\n    for word in text:\n        if word not in stopwords.words(\"english\"):\n            L.append(word)\n    return L        ","metadata":{"execution":{"iopub.status.busy":"2024-03-21T11:40:54.350592Z","iopub.status.idle":"2024-03-21T11:40:54.351185Z","shell.execute_reply.started":"2024-03-21T11:40:54.350991Z","shell.execute_reply":"2024-03-21T11:40:54.351009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"remove_stop([\"1\",\"thought\",\"this\",\"was\",\"a\",\"wonderful\",\"bliss\"])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"tokenized_review\"]=df[\"tokenized_review\"].apply(remove_stopwords)","metadata":{"execution":{"iopub.status.busy":"2024-03-21T11:40:54.352656Z","iopub.status.idle":"2024-03-21T11:40:54.353554Z","shell.execute_reply.started":"2024-03-21T11:40:54.353299Z","shell.execute_reply":"2024-03-21T11:40:54.353330Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## EDA","metadata":{}},{"cell_type":"code","source":"# I will create columns on length and word  of the review  adn we will try to find out \n# weather that feature is helpul or not \n# I will create a word  cloud feature also \n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"review\"]=df[\"tokenized_review\"].apply(lambda x:\" \".join(x))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"char_len\"]=df[\"review\"].str.len()\ndf[\"word_len\"]=df[\"tokenized_review\"].apply(len)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"displots \n### most reviews are in this range but is this gonna help us check that out new feature is helpful or not ","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.displot(df[\"char_length\"])\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"tokenized_review\"].sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[df[\"sentiment\"]==\"positive\"]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[df[\"sentiment\"]==\"positive\"][\"char_length\"]\ndf[df[\"sentiment\"]==\"negative\"][\"char_length\"]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##  if their is diffrence then we can see the feature i have created is helpful \n","metadata":{}},{"cell_type":"code","source":"df[\"tokenized_review\"].sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#common unigram/bigrams and trigrams \nfrom nltk import ngrams\n\npd.Series(ngrams(df['tokenized_review'].sum(),2)).value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#common unigram/bigrams and trigrams \nfrom nltk import ngrams\n\npd.Series(ngrams(df['tokenized_review'].sum(),3)).value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# word cloud \n\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize = (20,20)) # Positive Review Text\nwc = WordCloud(width = 1600 , height = 800).generate(\" \".join(df[df['sentiment'] == 'positive']['review']))\nplt.imshow(wc)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from wordcloud import WordCloud\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize = (20,20)) # Negative\nwc = WordCloud(width = 1600 , height = 800).generate(\" \".join(df[df['sentiment'] == 'negative']['review']))\nplt.imshow(wc)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# BoW\n\nfrom sklearn.feature_extraction.text import CountVectorizer\ncount_vectorizer = CountVectorizer(max_features=5000,ngram_range=(1,3))\nbag_of_words = count_vectorizer.fit_transform(df['review'])\nbag_of_words = pd.DataFrame(bag_of_words.toarray(),columns = count_vectorizer.get_feature_names())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.decomposition import PCA\n\npca = PCA(n_components=2)\npca_result = pca.fit_transform(bag_of_words.values)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.scatterplot(pca_result[:,0],pca_result[:,1],hue=df['sentiment'])","metadata":{},"execution_count":null,"outputs":[]}]}